{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for training information retrieval models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.functions import udf, size, explode, col, countDistinct, collect_list, monotonically_increasing_id, row_number\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS as gensim_words\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import os\n",
    "\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Normalizer as Normalizer_L2\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words('english')) \\\n",
    "                    .union(set(stopwords.words('german'))) \\\n",
    "                    .union(set(stopwords.words('french')))\n",
    "gensim_stopwords = set(gensim_words)\n",
    "spacy_stopwords = sp.Defaults.stop_words\n",
    "# https://countwordsfree.com/stopwords\n",
    "cwf_stopwords = set(line.strip() for line in open('stop_words.txt'))\n",
    "\n",
    "all_stopwords = list( nltk_stopwords \\\n",
    "                        .union(gensim_stopwords) \\\n",
    "                        .union(spacy_stopwords) \\\n",
    "                        .union(cwf_stopwords) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Context and SQL Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the right paths on local machine\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "os.environ[\"PYSPARK_PYTHON\"] = '/usr/bin/python3.7'\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = '/usr/bin/python3.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a SparkSession\n",
      "Created a SparkContext\n",
      "Created a SQLContext\n"
     ]
    }
   ],
   "source": [
    "# Start spark session configured for spark nlp\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .appName('SDDM') \\\n",
    "        .config('spark.driver.memory', '8g') \\\n",
    "        .config('spark.executor.memory', '8g') \\\n",
    "        .config('spark.memory.fraction', '0.8') \\\n",
    "        .config('spark.executor.cores', '8') \\\n",
    "        .config('spark.local.dir', '/home/rikz/Documents/Master/Semester2/SDDM/data/tmp') \\\n",
    "        .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0') \\\n",
    "        .getOrCreate()\n",
    "print(\"Created a SparkSession\")\n",
    "sc = spark.sparkContext\n",
    "print(\"Created a SparkContext\")\n",
    "sqlContext = SQLContext(sc)\n",
    "print(\"Created a SQLContext\")\n",
    "\n",
    "#         .config('spark.local.dir', '/data/s1847503/SDDM/tmp') \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into a SQLContext Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|_c0|            paper_id|               title|        list_authors|           full_text|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|           question0|                   -|                   -|How does temperat...|\n",
      "|  1|           question1|                   -|                   -|Seasonality of tr...|\n",
      "|  2|           question2|                   -|                   -|Effectiveness of ...|\n",
      "|  3|           question3|                   -|                   -|Effectiveness of ...|\n",
      "|  4|           question4|                   -|                   -|Effectiveness of ...|\n",
      "|  5|           question5|                   -|                   -|Effectiveness of ...|\n",
      "|  6|           question6|                   -|                   -|Effectiveness of ...|\n",
      "|  7|           question7|                   -|                   -|Effectiveness of ...|\n",
      "|  8|           question8|                   -|                   -|Significant chang...|\n",
      "|  9|           question9|                   -|                   -|Effectiveness of ...|\n",
      "| 10|20ee844014e6b7c91...|Coronavirus disea...|['John P A Ioanni...|\"The evolving cor...|\n",
      "| 11|3d2e51a4d7e9699e4...|COVID-19 and mate...|                  []|tems to ensure fo...|\n",
      "| 12|dd4cba9cda9f49ba9...|Systematic review...|                  []|Coronavirus has k...|\n",
      "| 13|2ef0ac31fd85f28b5...|SARS-CoV-Encoded ...|['Lucía Morales',...|In Brief SARS-CoV...|\n",
      "| 14|4bae3f6031a50a23b...|Effect of HA330 r...|['Xuefeng Xu', 'C...|\"The acute respir...|\n",
      "| 15|150b0fed0020d4549...|Traditional Chine...|           ['Ke He']|\"Traditional medi...|\n",
      "| 16|0ed26fea4f7e1a99d...|A new coronavirus...|['Fan Wu', 'Su Zh...|a Amino acids of ...|\n",
      "| 17|4b9e5d0ffdac80fba...|Article history: ...|['Kyung Sook Jung...|The major communi...|\n",
      "| 18|41fadbfc4def2200b...|49 Intellectual P...|                  []|\"Use of biotechno...|\n",
      "| 19|a8a2882316256ca57...|Region-resolved p...|['Hao-Liang Hu', ...|especially mitral...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.format('csv').options(header='true', maxColumns=2000000) \\\n",
    "        .load('/home/rikz/Documents/Master/Semester2/SDDM/data/data.csv')\n",
    "#       .load('/data/s1847503/SDDM/newdata/data.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|            paper_id|publish_time|               title|                 doi|             journal|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|d1aafb70c066a2068...|  2001-07-04|Clinical features...|10.1186/1471-2334...|      BMC Infect Dis|\n",
      "|6b0567729c2143a66...|  2000-08-15|Nitric oxide: a p...|        10.1186/rr14|          Respir Res|\n",
      "|06ced00a5fc042159...|  2000-08-25|Surfactant protei...|        10.1186/rr19|          Respir Res|\n",
      "|348055649b6b8cf2b...|  2001-02-22|Role of endotheli...|        10.1186/rr44|          Respir Res|\n",
      "|5f48792a5fa08bed9...|  2001-05-11|Gene expression i...|        10.1186/rr61|          Respir Res|\n",
      "|b2897e1277f566411...|  2001-12-17|Sequence requirem...|10.1093/emboj/20....|    The EMBO Journal|\n",
      "|3bb07ea10432f7738...|  2001-03-08|Debate: Transfusi...|       10.1186/cc987|           Crit Care|\n",
      "|5806726a24dc91de3...|  2001-05-02|The 21st Internat...|      10.1186/cc1013|           Crit Care|\n",
      "|faaf1022ccfe93b03...|  2003-08-07|Heme oxygenase-1 ...|10.1186/1465-9921...|          Respir Res|\n",
      "|5b44feca5d6ffaaeb...|  2003-09-01|Technical Descrip...| 10.1197/jamia.m1345|Journal of the Am...|\n",
      "|9d4e3e8eb092d5ed2...|  2000-04-17|Conservation of p...|10.1093/emboj/19....|              EMBO J|\n",
      "|14e0cac6e86d62859...|  2000-09-01|Heterogeneous nuc...|10.1093/emboj/19....|    The EMBO Journal|\n",
      "|d09b79026117ec9fa...|  2003-12-12|A Method to Ident...|       10.1251/bpo66|  Biol Proced Online|\n",
      "|44102e3e69e70ad2a...|  2000-08-01|Vaccinia virus in...|10.1093/emboj/19....|    The EMBO Journal|\n",
      "|6e8517cb25ff228cb...|  2004-01-20|The site of origi...|10.1186/1479-5876...|        J Transl Med|\n",
      "|30a4842a2e257f725...|  2004-05-26|Multi-faceted, mu...|10.1186/1742-4690...|       Retrovirology|\n",
      "|6a8ac55ea2a1fbd99...|  2004-03-31|Herpes simplex vi...|      10.1186/cc2850|           Crit Care|\n",
      "|367af6bb9a8bbda02...|  2004-08-06|Logistics of comm...|10.1186/1471-2458...|   BMC Public Health|\n",
      "|4df2c6eecb985fcb2...|  2004-09-27|Protection of pul...|10.1186/1465-9921...|          Respir Res|\n",
      "|83b05e8afa6cbe7a6...|  2005-01-03|Bioinformatic map...|10.1186/1471-2164...|        BMC Genomics|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_metadata = sqlContext.read.format('csv').options(header='true') \\\n",
    "                .load('/home/rikz/Documents/Master/Semester2/SDDM/data/metadata.csv') \\\n",
    "                .select(col('sha').alias('paper_id'), 'publish_time', 'title', 'doi', 'journal')\n",
    "\n",
    "df_metadata.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for text\n",
    "document_assembler = DocumentAssembler() \\\n",
    "                        .setInputCol('full_text') \\\n",
    "                        .setOutputCol('document')\n",
    "\n",
    "# Tokenizer divides the text into tokens\n",
    "tokenizer = Tokenizer() \\\n",
    "                .setInputCols(['document']) \\\n",
    "                .setOutputCol('tokens')\n",
    "\n",
    "# Finisher converts tokens to human-readable output (we need the tokens for determining the text lengths)\n",
    "finisher_tokens = Finisher() \\\n",
    "                        .setInputCols(['tokens']) \\\n",
    "                        .setCleanAnnotations(False)\n",
    "\n",
    "# Normalizer removes punctuation, numbers etc.\n",
    "normalizer = Normalizer() \\\n",
    "                .setInputCols(['tokens']) \\\n",
    "                .setOutputCol('normalized') \\\n",
    "                .setLowercase(True)\n",
    "\n",
    "# Lemmatizer changes each word to its lemma\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "                .setInputCols(['normalized']) \\\n",
    "                .setOutputCol('lemma')\n",
    "\n",
    "# StopWordsCleaner removes stop words    \n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "                        .setInputCols(['lemma']) \\\n",
    "                        .setOutputCol('clean_lemma') \\\n",
    "                        .setCaseSensitive(False).setStopWords(all_stopwords)\n",
    "\n",
    "# Finisher converts clean tokens to human-readable output\n",
    "finisher = Finisher() \\\n",
    "            .setInputCols(['clean_lemma']) \\\n",
    "            .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for fully preprocessing the text\n",
    "pipeline = Pipeline() \\\n",
    "            .setStages([\n",
    "                document_assembler,\n",
    "                tokenizer,\n",
    "                normalizer,\n",
    "                lemmatizer,\n",
    "                stopwords_cleaner,\n",
    "                finisher_tokens,\n",
    "                finisher\n",
    "             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|question_id|           full_text|        preprocessed|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          0|How does temperat...|[temperature, hum...|\n",
      "|          1|Seasonality of tr...|[seasonality, tra...|\n",
      "|          2|Effectiveness of ...|[effectiveness, i...|\n",
      "|          3|Effectiveness of ...|[effectiveness, p...|\n",
      "|          4|Effectiveness of ...|[effectiveness, s...|\n",
      "|          5|Effectiveness of ...|[effectiveness, c...|\n",
      "|          6|Effectiveness of ...|[effectiveness, m...|\n",
      "|          7|Effectiveness of ...|[effectiveness, c...|\n",
      "|          8|Significant chang...|[change, transmis...|\n",
      "|          9|Effectiveness of ...|[effectiveness, w...|\n",
      "+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = sqlContext.read.format('csv').options(header='true').load('/data/s1847503/SDDM/newdata/questions.csv')\n",
    "questions = sqlContext.read.format('csv').options(header='true').load('/home/rikz/Documents/Master/Semester2/SDDM/data/questions.csv')\n",
    "questions_clean = pipeline.fit(questions).transform(questions)\n",
    "questions_clean = questions_clean.select('question_id', 'full_text', col('finished_clean_lemma').alias('preprocessed'))\n",
    "questions_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seasonality of transmission'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the question from 0 to 9\n",
    "question_num = 1\n",
    "\n",
    "questions_clean = questions_clean.filter(questions_clean.question_id == question_num)\n",
    "q = questions_clean.first().full_text\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing empty papers and duplicates: 510 rows.\n",
      "Removed empty papers\n",
      "Removed duplicates\n",
      "After removing empty papers and duplicates: 509 rows.\n",
      "\n",
      "+---+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "| id|            paper_id|               title|           full_text|text_length|        preprocessed|\n",
      "+---+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "| 54|86c3b8562c3094e95...|Title: A Feminist...|\"Natural disaster...|        498|[natural, disaste...|\n",
      "| 56|55743de644f6eda86...|Anti-microbial im...|Chronic obstructi...|       3601|[chronic, obstruc...|\n",
      "|100|690178e12695c5fdc...|                null|As of this date, ...|       1668|[case, covid, rep...|\n",
      "| 79|5009e8203ed264e9d...|Coronavirus Rever...|\"1 Introduction T...|        316|[introduction, ta...|\n",
      "|278|7f7940bc0ca1e1986...|Update in the tre...|Each year respira...|       7145|[year, respirator...|\n",
      "|396|0d76b14e9ae608525...|Viral Life Cycles...|\"Electron microsc...|        437|[electron, micros...|\n",
      "|234|86e5d3988edd1aa3d...|Potent Antiviral ...|\"The COVID-19 out...|         91|[covid, outbreak,...|\n",
      "|205|3c26c921c42bb4b2c...|Viral Infections ...|\"This article is ...|        300|[article, protect...|\n",
      "| 92|be05821eac40596ed...|Structural charac...|Emerging infectio...|       6360|[emerge, infectio...|\n",
      "|423|bdd32f74cc1be5920...|Anti-In£uenzaViru...|The replicative c...|       7366|[replicative, cyc...|\n",
      "|495|263f12984a135507e...|Asymmetric effect...|\"A growing body o...|       1032|[grow, body, argu...|\n",
      "|474|9448084d08566af74...|Tropical Medicine...|\"The global disco...|       4480|[global, discover...|\n",
      "| 13|2ef0ac31fd85f28b5...|SARS-CoV-Encoded ...|In Brief SARS-CoV...|       6708|[sarscov, exacerb...|\n",
      "|294|b4208007d70786df3...|Initial stage of ...|There are various...|        693|[scenario, model,...|\n",
      "|319|1af8c29bad3166064...|                null|explained that in...|       1263|[explain, growth,...|\n",
      "|212|42ce4e5eac6e69f5d...|The development o...|\"Infectious conju...|       1053|[infectious, conj...|\n",
      "|419|fc7c462f4b3c1a7e4...|Human Coronavirus...|\"T he recent iden...|       1306|[identification, ...|\n",
      "|362|5c3bfe9b503d23810...|Potential anti-SA...|A novel coronavir...|       2292|[coronavirus, sev...|\n",
      "| 69|22264c65eb6c14ba9...|Quality control i...|Although the pote...|       1439|[potential, mngs,...|\n",
      "|203|57b1179e96db85fd1...|A novel intracell...|Bovine viral diar...|       5785|[bovine, viral, d...|\n",
      "+---+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peprocess the data\n",
    "df = pipeline.fit(df).transform(df)\n",
    "df = df.select('*', size('finished_tokens').alias('text_length'))\n",
    "\n",
    "print(\"Before removing empty papers and duplicates: {} rows.\".format(df.count()))\n",
    "df = df.dropna(subset='full_text')\n",
    "print(\"Removed empty papers\")\n",
    "df = df.dropDuplicates(subset=['full_text'])\n",
    "print(\"Removed duplicates\")\n",
    "print(\"After removing empty papers and duplicates: {} rows.\".format(df.count()))\n",
    "print()\n",
    "\n",
    "df = df.select(\n",
    "                col('_c0').alias('id'),\n",
    "                'paper_id',\n",
    "                'title',\n",
    "                'full_text',\n",
    "                'text_length',\n",
    "                col('finished_clean_lemma').alias('preprocessed')\n",
    "            )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF matrix for papers\n",
    "tf_p = []\n",
    "tf_idf_papers = []\n",
    "\n",
    "tf_p = HashingTF(inputCol='preprocessed', outputCol='tf') \\\n",
    "                    .transform(df)\n",
    "\n",
    "tf_idf_papers = IDF(inputCol='tf', outputCol='feature') \\\n",
    "                        .fit(tf_p) \\\n",
    "                        .transform(tf_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF matrix for questions\n",
    "tf_q = []\n",
    "tf_idf_questions = []\n",
    "\n",
    "tf_q = HashingTF(inputCol='preprocessed', outputCol='tf') \\\n",
    "                    .transform(questions_clean)\n",
    "\n",
    "tf_idf_questions = IDF(inputCol='tf', outputCol='feature') \\\n",
    "                        .fit(tf_p) \\\n",
    "                        .transform(tf_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_papers.show()\n",
    "tf_idf_questions = tf_idf_questions.select('question_id', 'feature')\n",
    "tf_idf_papers = tf_idf_papers.select('id', 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute L2-norm for papers and questions\n",
    "normalizer_L2 = Normalizer_L2(inputCol='feature', outputCol='norm')\n",
    "tf_idf_papers = normalizer_L2.transform(tf_idf_papers)\n",
    "tf_idf_questions = normalizer_L2.transform(tf_idf_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "matrix_q = IndexedRowMatrix(\n",
    "                tf_idf_questions \\\n",
    "                    .select('question_id', 'norm') \\\n",
    "                    .rdd.map(lambda row: IndexedRow(row.question_id, row.norm.toArray()))\n",
    "            ).toBlockMatrix()\n",
    "\n",
    "matrix_p = IndexedRowMatrix(\n",
    "                tf_idf_papers \\\n",
    "                    .select('id', 'norm') \\\n",
    "                    .rdd.map(lambda row: IndexedRow(row.id, row.norm.toArray()))\n",
    "            ).toBlockMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = matrix_p.multiply(matrix_q.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = sim_matrix.toLocalMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|          similarity|\n",
      "+---+--------------------+\n",
      "| 81|  0.1206854224779491|\n",
      "|378| 0.10925852912960747|\n",
      "|503|  0.0807954430250116|\n",
      "|330|  0.0605402359134014|\n",
      "|483|0.054653475088306654|\n",
      "|175| 0.05221709483415023|\n",
      "| 57| 0.04250770900626558|\n",
      "|379| 0.03903621434679915|\n",
      "|138| 0.03790675613575219|\n",
      "|113| 0.03703849652429182|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant = sc.parallelize(sim_matrix[:, question_num].tolist()) \\\n",
    "                .zipWithIndex() \\\n",
    "                .toDF(['similarity', 'id'])\n",
    "\n",
    "# Remove questions from the paper list\n",
    "# Sort on cosine similarity\n",
    "# Take the top 10 relevant documents\n",
    "relevant = relevant.select('id', 'similarity') \\\n",
    "                .filter(relevant.id > 9) \\\n",
    "                .sort(col('similarity').desc()) \\\n",
    "                .limit(10)\n",
    "\n",
    "relevant.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Seasonality of transmission\n",
      "\n",
      "Relevant Papers:\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|            paper_id|          similarity|\n",
      "+--------------------+--------------------+\n",
      "|3c8fa182d782957ad...|  0.1206854224779491|\n",
      "|6cab26f503af61365...| 0.10925852912960747|\n",
      "|faec3c682985aba0b...|  0.0807954430250116|\n",
      "|36c21939153187db3...|  0.0605402359134014|\n",
      "|12893aa539717df5c...|0.054653475088306654|\n",
      "|0f52f6ec3e15cc1cc...| 0.05221709483415023|\n",
      "|79d74f550f25e52d5...| 0.04250770900626558|\n",
      "|f9cc1ff1f9844f453...| 0.03903621434679915|\n",
      "|8ceaaa87a76db5f30...| 0.03790675613575219|\n",
      "|10b278160952f4290...| 0.03703849652429182|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the data of the 10 most relevant papers in order of relevance\n",
    "relevant_ids = [int(row.id) for row in relevant.collect()]\n",
    "print(\"Query: {}\".format(q))\n",
    "print()\n",
    "print(\"Relevant Papers:\")\n",
    "print()\n",
    "df_relevant = relevant.join(df.filter(df.id.isin(relevant_ids)), on=['id'], how='left_outer') \\\n",
    "                        .select('paper_id', 'similarity')\n",
    "df_relevant.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3c8fa182d782957ade3296881a99ac4bfe97cd4c</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>Airborne Microorganisms From Livestock Product...</td>\n",
       "      <td>10.1080/10643389.2012.746064</td>\n",
       "      <td>Crit Rev Environ Sci Technol</td>\n",
       "      <td>0.120685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6cab26f503af61365106a1be2eaeba79f1096381</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>Evolving Transmission Network Dynamics of COVI...</td>\n",
       "      <td>10.1101/2020.05.07.20091769</td>\n",
       "      <td>medRxiv : the preprint server for health sciences</td>\n",
       "      <td>0.109259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faec3c682985aba0b6114b0f9865e66d19c64e17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.080795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36c21939153187db30a91c907b300c37da9577e7</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>Severe Acute Respiratory Syndrome Coronavirus ...</td>\n",
       "      <td>10.3201/eid2607.200591</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>0.060540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12893aa539717df5ccaa94d15d84cb5c057fcdbf</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>COVID-19 trend in Bangladesh: deviation from e...</td>\n",
       "      <td>10.1101/2020.05.31.20118745</td>\n",
       "      <td>None</td>\n",
       "      <td>0.054653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f52f6ec3e15cc1cc45803c3cb81618d5ee82b7a</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>Coherence of Influenza Surveillance Data acros...</td>\n",
       "      <td>10.1371/journal.pone.0169199</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>0.052217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79d74f550f25e52d549aa795801c0d8eb8c46dac</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.042508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f9cc1ff1f9844f453de804c26bda98ddda1b11eb</td>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>Severe cytomegalovirus (CMV) community-acquire...</td>\n",
       "      <td>10.1016/j.hrtlng.2008.05.008</td>\n",
       "      <td>Heart &amp; Lung</td>\n",
       "      <td>0.039036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ceaaa87a76db5f305006a242a690c597b302a5c</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>Andronov–Hopf and Neimark–Sacker bifurcations ...</td>\n",
       "      <td>10.1186/s13662-020-02646-5</td>\n",
       "      <td>Adv Differ Equ</td>\n",
       "      <td>0.037907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10b278160952f4290b2b2465b4689de75086afb5</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>epiDMS: Data Management and Analytics for Deci...</td>\n",
       "      <td>10.1093/infdis/jiw305</td>\n",
       "      <td>J Infect Dis</td>\n",
       "      <td>0.037038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id publish_time  \\\n",
       "6  3c8fa182d782957ade3296881a99ac4bfe97cd4c   2014-04-16   \n",
       "4  6cab26f503af61365106a1be2eaeba79f1096381   2020-05-12   \n",
       "8  faec3c682985aba0b6114b0f9865e66d19c64e17         None   \n",
       "9  36c21939153187db30a91c907b300c37da9577e7   2020-07-05   \n",
       "7  12893aa539717df5ccaa94d15d84cb5c057fcdbf   2020-06-03   \n",
       "2  0f52f6ec3e15cc1cc45803c3cb81618d5ee82b7a   2016-12-30   \n",
       "0  79d74f550f25e52d549aa795801c0d8eb8c46dac         None   \n",
       "5  f9cc1ff1f9844f453de804c26bda98ddda1b11eb   2009-06-30   \n",
       "1  8ceaaa87a76db5f305006a242a690c597b302a5c   2020-04-29   \n",
       "3  10b278160952f4290b2b2465b4689de75086afb5   2016-12-01   \n",
       "\n",
       "                                               title  \\\n",
       "6  Airborne Microorganisms From Livestock Product...   \n",
       "4  Evolving Transmission Network Dynamics of COVI...   \n",
       "8                                               None   \n",
       "9  Severe Acute Respiratory Syndrome Coronavirus ...   \n",
       "7  COVID-19 trend in Bangladesh: deviation from e...   \n",
       "2  Coherence of Influenza Surveillance Data acros...   \n",
       "0                                               None   \n",
       "5  Severe cytomegalovirus (CMV) community-acquire...   \n",
       "1  Andronov–Hopf and Neimark–Sacker bifurcations ...   \n",
       "3  epiDMS: Data Management and Analytics for Deci...   \n",
       "\n",
       "                            doi  \\\n",
       "6  10.1080/10643389.2012.746064   \n",
       "4   10.1101/2020.05.07.20091769   \n",
       "8                          None   \n",
       "9        10.3201/eid2607.200591   \n",
       "7   10.1101/2020.05.31.20118745   \n",
       "2  10.1371/journal.pone.0169199   \n",
       "0                          None   \n",
       "5  10.1016/j.hrtlng.2008.05.008   \n",
       "1    10.1186/s13662-020-02646-5   \n",
       "3         10.1093/infdis/jiw305   \n",
       "\n",
       "                                             journal  similarity  \n",
       "6                       Crit Rev Environ Sci Technol    0.120685  \n",
       "4  medRxiv : the preprint server for health sciences    0.109259  \n",
       "8                                               None    0.080795  \n",
       "9                                   Emerg Infect Dis    0.060540  \n",
       "7                                               None    0.054653  \n",
       "2                                           PLoS One    0.052217  \n",
       "0                                               None    0.042508  \n",
       "5                                       Heart & Lung    0.039036  \n",
       "1                                     Adv Differ Equ    0.037907  \n",
       "3                                       J Infect Dis    0.037038  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the summary table with the relevant paper from the metadata\n",
    "df_relevant = df_relevant.join(df_metadata, on=['paper_id'], how='left_outer') \\\n",
    "                            .select('paper_id', 'publish_time', 'title', 'doi', 'journal', 'similarity') \\\n",
    "                            .toPandas() \\\n",
    "                            .sort_values(by='similarity', ascending=False)\n",
    "df_relevant.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table extracted and sent to csv file.\n"
     ]
    }
   ],
   "source": [
    "# Send the summary table to a csv file\n",
    "df_relevant.to_csv('/home/rikz/Documents/Master/Semester2/SDDM/SDDM/summary_tables/{}.csv' \\\n",
    "                   .format(q.lower().replace(' ', '_')), index=True)\n",
    "print(\"Summary table extracted and sent to csv file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "word2Vec = Word2Vec(inputCol='preprocessed', outputCol='word_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2Vec.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_clean = model.transform(questions_clean)\n",
    "ques_vec = questions_clean.first().word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between a document vector and a question vector\n",
    "def cossim(doc_vec): \n",
    "    global ques_vec\n",
    "    sim = np.dot(doc_vec, ques_vec) / np.sqrt(np.dot(doc_vec, ques_vec)) / np.sqrt(np.dot(doc_vec, ques_vec)) \n",
    "    return float(sim)\n",
    "\n",
    "cossim_udf = udf(cossim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select('id', cossim_udf('word_vector').alias('similarity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Before removing empty papers: {} rows.\".format(df2.count()))\n",
    "print(\"x\")\n",
    "df2 = df2.filter(df2.similarity.isNotNull())\n",
    "print(\"After removing empty papers 1: {} rows.\".format(df2.count()))\n",
    "df2 = df2.filter(df2.similarity != 'NaN')\n",
    "# df2 = df2.dropna(subset='similarity')\n",
    "print(\"After removing empty papers 2: {} rows.\".format(df2.count()))\n",
    "df2 = df2.orderBy('similarity', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [40821, 40931, 40823, 40776, 40831]\n",
    "for r in relevant:\n",
    "    print(df.filter(df.id == 40821).first().title)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Spark Context when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
