{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts the papers from json files and store all of them in one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6281bf3b0edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Open a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Get the paper id and title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DLNN/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List all directories where data is stored\n",
    "dirs = ['/data/s1847503/SDDM/newdata/document_parses/pdf_json/',\n",
    "        '/data/s1847503/SDDM/newdata/document_parses/pmc_json/'\n",
    "       ]\n",
    "\n",
    "# For each paper, store the id, title, authors, abstract and full text in a list with documents\n",
    "docs = []\n",
    "count = 0\n",
    "for d in dirs:\n",
    "    for file in os.listdir(d):\n",
    "        # Open a file\n",
    "        filename = d+file\n",
    "        j = json.load(open(filename, 'rb'))\n",
    "        \n",
    "        # Get the paper id and title\n",
    "        paper_id = j['paper_id']\n",
    "        title = j['metadata']['title']\n",
    "        \n",
    "        # Get a list with the authors\n",
    "        authors = j['metadata']['authors']\n",
    "        list_authors = []\n",
    "        for author in authors:\n",
    "            # Not every author has a middle name, handle those cases correctly\n",
    "            if(len(author['middle']) == 0):\n",
    "                middle = \" \"\n",
    "            else:\n",
    "                middle = \" \" + author['middle'][0] + \" \"\n",
    "            _author = author['first'] + middle + author['last']\n",
    "            list_authors.append(_author.strip())\n",
    "        \n",
    "        # Get the full text\n",
    "        full_text = \"\"\n",
    "        sections = []\n",
    "        for text in j['body_text']:\n",
    "            full_text += text['text'] + ' '\n",
    "            sections.append(text['text'])\n",
    "        \n",
    "        # Append everything to the document list\n",
    "        docs.append([count,paper_id,title,list_authors,full_text,sections])\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "# Convert the list to a Dataframe and send it to a csv file\n",
    "df = pd.DataFrame(docs, columns=['id','paper_id','title','list_authors','full_text', 'sections'])\n",
    "df.to_csv('/data/s1847503/SDDM/newdata/data.csv', index=False)\n",
    "print(\"Data extracted and sent to csv file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the queries from task 2 to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions extracted and sent to csv file.\n"
     ]
    }
   ],
   "source": [
    "question_path = '/data/s1847503/SDDM/newdata/Kaggle/target_tables/2_relevant_factors/'\n",
    "questions = []\n",
    "question_id = 0\n",
    "\n",
    "for file in os.listdir(question_path):\n",
    "    questions.append( [question_id, file.split(\".csv\")[0].replace('_', ' ')])\n",
    "    question_id += 1\n",
    "\n",
    "sr = pd.DataFrame(questions, columns=['question_id', 'full_text'])\n",
    "sr.to_csv('/data/s1847503/SDDM/newdata/questions.csv', index=False)\n",
    "print(\"Questions extracted and sent to csv file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
