{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.functions import udf, size, col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS as gensim_words\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import os\n",
    "\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stop words\n",
    "nltk_stopwords = set(stopwords.words('english')) \\\n",
    "                    .union(set(stopwords.words('german'))) \\\n",
    "                    .union(set(stopwords.words('french')))\n",
    "gensim_stopwords = set(gensim_words)\n",
    "spacy_stopwords = sp.Defaults.stop_words\n",
    "# https://countwordsfree.com/stopwords\n",
    "cwf_stopwords = set(line.strip() for line in open('stop_words.txt'))\n",
    "\n",
    "all_stopwords = list( nltk_stopwords \\\n",
    "                        .union(gensim_stopwords) \\\n",
    "                        .union(spacy_stopwords) \\\n",
    "                        .union(cwf_stopwords) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Context and SQL Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the right paths on local machine\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "os.environ[\"PYSPARK_PYTHON\"] = '/usr/bin/python3.7'\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = '/usr/bin/python3.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a SparkSession\n",
      "Created a SparkContext\n",
      "Created a SQLContext\n"
     ]
    }
   ],
   "source": [
    "# Start spark session configured for SparkNLP\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .appName('SDDM') \\\n",
    "        .config('spark.driver.memory', '8g') \\\n",
    "        .config('spark.executor.memory', '8g') \\\n",
    "        .config('spark.memory.fraction', '0.8') \\\n",
    "        .config('spark.executor.cores', '8') \\\n",
    "        .config('spark.local.dir', '/home/rikz/Documents/Master/Semester2/SDDM/data/tmp') \\\n",
    "        .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0') \\\n",
    "        .getOrCreate()\n",
    "print(\"Created a SparkSession\")\n",
    "sc = spark.sparkContext\n",
    "print(\"Created a SparkContext\")\n",
    "sqlContext = SQLContext(sc)\n",
    "print(\"Created a SQLContext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into a SQLContext Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|_c0|            paper_id|               title|        list_authors|           full_text|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|           question0|                   -|                   -|How does temperat...|\n",
      "|  1|           question1|                   -|                   -|Seasonality of tr...|\n",
      "|  2|           question2|                   -|                   -|Effectiveness of ...|\n",
      "|  3|           question3|                   -|                   -|Effectiveness of ...|\n",
      "|  4|           question4|                   -|                   -|Effectiveness of ...|\n",
      "|  5|           question5|                   -|                   -|Effectiveness of ...|\n",
      "|  6|           question6|                   -|                   -|Effectiveness of ...|\n",
      "|  7|           question7|                   -|                   -|Effectiveness of ...|\n",
      "|  8|           question8|                   -|                   -|Significant chang...|\n",
      "|  9|           question9|                   -|                   -|Effectiveness of ...|\n",
      "| 10|20ee844014e6b7c91...|Coronavirus disea...|['John P A Ioanni...|\"The evolving cor...|\n",
      "| 11|3d2e51a4d7e9699e4...|COVID-19 and mate...|                  []|tems to ensure fo...|\n",
      "| 12|dd4cba9cda9f49ba9...|Systematic review...|                  []|Coronavirus has k...|\n",
      "| 13|2ef0ac31fd85f28b5...|SARS-CoV-Encoded ...|['Luc√≠a Morales',...|In Brief SARS-CoV...|\n",
      "| 14|4bae3f6031a50a23b...|Effect of HA330 r...|['Xuefeng Xu', 'C...|\"The acute respir...|\n",
      "| 15|150b0fed0020d4549...|Traditional Chine...|           ['Ke He']|\"Traditional medi...|\n",
      "| 16|0ed26fea4f7e1a99d...|A new coronavirus...|['Fan Wu', 'Su Zh...|a Amino acids of ...|\n",
      "| 17|4b9e5d0ffdac80fba...|Article history: ...|['Kyung Sook Jung...|The major communi...|\n",
      "| 18|41fadbfc4def2200b...|49 Intellectual P...|                  []|\"Use of biotechno...|\n",
      "| 19|a8a2882316256ca57...|Region-resolved p...|['Hao-Liang Hu', ...|especially mitral...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = sqlContext.read.format('csv').options(header='true', maxColumns=2000000) \\\n",
    "        .load('/home/rikz/Documents/Master/Semester2/SDDM/data/data.csv')\n",
    "#       .load('/data/s1847503/SDDM/newdata/data.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|            paper_id|publish_time|               title|                 doi|             journal|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|d1aafb70c066a2068...|  2001-07-04|Clinical features...|10.1186/1471-2334...|      BMC Infect Dis|\n",
      "|6b0567729c2143a66...|  2000-08-15|Nitric oxide: a p...|        10.1186/rr14|          Respir Res|\n",
      "|06ced00a5fc042159...|  2000-08-25|Surfactant protei...|        10.1186/rr19|          Respir Res|\n",
      "|348055649b6b8cf2b...|  2001-02-22|Role of endotheli...|        10.1186/rr44|          Respir Res|\n",
      "|5f48792a5fa08bed9...|  2001-05-11|Gene expression i...|        10.1186/rr61|          Respir Res|\n",
      "|b2897e1277f566411...|  2001-12-17|Sequence requirem...|10.1093/emboj/20....|    The EMBO Journal|\n",
      "|3bb07ea10432f7738...|  2001-03-08|Debate: Transfusi...|       10.1186/cc987|           Crit Care|\n",
      "|5806726a24dc91de3...|  2001-05-02|The 21st Internat...|      10.1186/cc1013|           Crit Care|\n",
      "|faaf1022ccfe93b03...|  2003-08-07|Heme oxygenase-1 ...|10.1186/1465-9921...|          Respir Res|\n",
      "|5b44feca5d6ffaaeb...|  2003-09-01|Technical Descrip...| 10.1197/jamia.m1345|Journal of the Am...|\n",
      "|9d4e3e8eb092d5ed2...|  2000-04-17|Conservation of p...|10.1093/emboj/19....|              EMBO J|\n",
      "|14e0cac6e86d62859...|  2000-09-01|Heterogeneous nuc...|10.1093/emboj/19....|    The EMBO Journal|\n",
      "|d09b79026117ec9fa...|  2003-12-12|A Method to Ident...|       10.1251/bpo66|  Biol Proced Online|\n",
      "|44102e3e69e70ad2a...|  2000-08-01|Vaccinia virus in...|10.1093/emboj/19....|    The EMBO Journal|\n",
      "|6e8517cb25ff228cb...|  2004-01-20|The site of origi...|10.1186/1479-5876...|        J Transl Med|\n",
      "|30a4842a2e257f725...|  2004-05-26|Multi-faceted, mu...|10.1186/1742-4690...|       Retrovirology|\n",
      "|6a8ac55ea2a1fbd99...|  2004-03-31|Herpes simplex vi...|      10.1186/cc2850|           Crit Care|\n",
      "|367af6bb9a8bbda02...|  2004-08-06|Logistics of comm...|10.1186/1471-2458...|   BMC Public Health|\n",
      "|4df2c6eecb985fcb2...|  2004-09-27|Protection of pul...|10.1186/1465-9921...|          Respir Res|\n",
      "|83b05e8afa6cbe7a6...|  2005-01-03|Bioinformatic map...|10.1186/1471-2164...|        BMC Genomics|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "df_metadata = sqlContext.read.format('csv').options(header='true') \\\n",
    "                .load('/home/rikz/Documents/Master/Semester2/SDDM/data/metadata.csv') \\\n",
    "                .select(col('sha').alias('paper_id'), 'publish_time', 'title', 'doi', 'journal')\n",
    "\n",
    "df_metadata.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for text\n",
    "document_assembler = DocumentAssembler() \\\n",
    "                        .setInputCol('full_text') \\\n",
    "                        .setOutputCol('document')\n",
    "\n",
    "# Tokenizer divides the text into tokens\n",
    "tokenizer = Tokenizer() \\\n",
    "                .setInputCols(['document']) \\\n",
    "                .setOutputCol('tokens')\n",
    "\n",
    "# Finisher converts tokens to human-readable output (we need the tokens for determining the text lengths)\n",
    "finisher_tokens = Finisher() \\\n",
    "                        .setInputCols(['tokens']) \\\n",
    "                        .setCleanAnnotations(False)\n",
    "\n",
    "# Normalizer removes punctuation, numbers etc.\n",
    "normalizer = Normalizer() \\\n",
    "                .setInputCols(['tokens']) \\\n",
    "                .setOutputCol('normalized') \\\n",
    "                .setLowercase(True)\n",
    "\n",
    "# Lemmatizer changes each word to its lemma\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "                .setInputCols(['normalized']) \\\n",
    "                .setOutputCol('lemma')\n",
    "\n",
    "# StopWordsCleaner removes stop words    \n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "                        .setInputCols(['lemma']) \\\n",
    "                        .setOutputCol('clean_lemma') \\\n",
    "                        .setCaseSensitive(False).setStopWords(all_stopwords)\n",
    "\n",
    "# Finisher converts clean tokens to human-readable output\n",
    "finisher = Finisher() \\\n",
    "            .setInputCols(['clean_lemma']) \\\n",
    "            .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for fully preprocessing the text\n",
    "pipeline = Pipeline() \\\n",
    "            .setStages([\n",
    "                document_assembler,\n",
    "                tokenizer,\n",
    "                normalizer,\n",
    "                lemmatizer,\n",
    "                stopwords_cleaner,\n",
    "                finisher_tokens,\n",
    "                finisher\n",
    "             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|question_id|           full_text|        preprocessed|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          0|How does temperat...|[temperature, hum...|\n",
      "|          1|Seasonality of tr...|[seasonality, tra...|\n",
      "|          2|Effectiveness of ...|[effectiveness, i...|\n",
      "|          3|Effectiveness of ...|[effectiveness, p...|\n",
      "|          4|Effectiveness of ...|[effectiveness, s...|\n",
      "|          5|Effectiveness of ...|[effectiveness, c...|\n",
      "|          6|Effectiveness of ...|[effectiveness, m...|\n",
      "|          7|Effectiveness of ...|[effectiveness, c...|\n",
      "|          8|Significant chang...|[change, transmis...|\n",
      "|          9|Effectiveness of ...|[effectiveness, w...|\n",
      "+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = sqlContext.read.format('csv').options(header='true').load('/data/s1847503/SDDM/newdata/questions.csv')\n",
    "questions = sqlContext.read.format('csv').options(header='true').load('/home/rikz/Documents/Master/Semester2/SDDM/data/questions.csv')\n",
    "questions_clean = pipeline.fit(questions).transform(questions)\n",
    "questions_clean = questions_clean.select('question_id', 'full_text', col('finished_clean_lemma').alias('preprocessed'))\n",
    "questions_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Effectiveness of inter inner travel restriction'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a question (from 0 to 9)\n",
    "question_num = 2\n",
    "\n",
    "questions_clean = questions_clean.filter(questions_clean.question_id == question_num)\n",
    "q = questions_clean.first().full_text\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty papers\n",
      "Removed duplicates\n",
      "\n",
      "+---+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "| id|            paper_id|               title|           full_text|text_length|        preprocessed|\n",
      "+---+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "|263|6cb2eced687ea9da4...|Medical recommend...|\"In early 2020, t...|       1224|[early, face, glo...|\n",
      "|468|9482e5881613ae262...|Oral vaccination ...|Helicobacter pylo...|       3705|[helicobacter, py...|\n",
      "|491|c3ba4e042c5173d4a...|Thomas Gr√ºnewald,...|\"Die Versorgung v...|        205|[versorgung, pati...|\n",
      "|173|e639fc8b330785fb2...|            Vaccines|\"Since vaccinatio...|        537|[vaccination, doc...|\n",
      "|201|8645437ad8a6f8538...|Accessibility and...|The terminology o...|       8079|[terminology, acc...|\n",
      "|224|121638b718d18f7bb...|JOURNAL OF MEDICA...|\"Adenoviruses are...|        793|[adenoviruses, do...|\n",
      "|200|4bc77a5504262d2f8...|A Fuzzy Model for...|\"These rates also...|         67|[rate, impact, pr...|\n",
      "|144|c4213fb7b0fdd8926...|Forecasting COVID...|ORCID iD: https:/...|        990|[orcid, httpsorci...|\n",
      "|249|cc367798b29defe46...|Modeling State In...|\"A and B are fixe...|        219|[matrix, vector, ...|\n",
      "|131|0823046d9ca5204f9...|Is the anti-psych...|\"Severe acute res...|       2103|[severe, acute, r...|\n",
      "| 62|249562b091482dd3e...|Viral Respiratory...|Common viral resp...|       1795|[common, viral, r...|\n",
      "|245|1043007c52a94b83c...|A Major Role of M...|MHV3 constitutes ...|       1933|[mhv, constitute,...|\n",
      "|183|71d2ad06792c5adb2...|Immune-complex gl...|Recently, the Wor...|       3657|[small, animal, v...|\n",
      "|116|744d673951034c6c8...|                null|\"Recent study rep...|         53|[report, journal,...|\n",
      "|305|b8d39ed5f718e5510...|Idiopathic Inters...|Over 200 causes o...|       2686|[interstitial, lu...|\n",
      "|501|f9426eca19bf968f0...|\"\"\"We're staying ...|['Andr√©s Losada-B...|         27|[andr√©s, losadaba...|\n",
      "|109|058d0d90dbc0a78ed...|                null|\"environmentalist...|        463|[environmentalist...|\n",
      "| 61|714dd1fe1309414e8...|Several countries...|It has been few m...|       4266|[month, confirm, ...|\n",
      "|223|b83d5dc2ac33c3e6d...|Spectrum of Virus...|\"istered, laborat...|        608|[istered, laborat...|\n",
      "|383|cda1f45974f3f33fa...|Sophie Knipper 1 ...|\"In order to rest...|        111|[order, restrain,...|\n",
      "+---+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peprocess the data\n",
    "df = pipeline.fit(df).transform(df)\n",
    "df = df.select('*', size('finished_tokens').alias('text_length'))\n",
    "\n",
    "df = df.dropna(subset=['paper_id', 'full_text'])\n",
    "print(\"Removed empty papers\")\n",
    "df = df.dropDuplicates(subset=['paper_id', 'full_text'])\n",
    "print(\"Removed duplicates\")\n",
    "print()\n",
    "\n",
    "df = df.select(\n",
    "                col('_c0').alias('id'),\n",
    "                'paper_id',\n",
    "                'title',\n",
    "                'full_text',\n",
    "                'text_length',\n",
    "                col('finished_clean_lemma').alias('preprocessed')\n",
    "            )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_after = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing time: 14.461075067520142 sec\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing time: {} sec'.format(time_after-time_before) )\n",
    "# Small dataset: ~15 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "word2Vec = Word2Vec(inputCol='preprocessed', outputCol='word_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for the papers and get the vectors for all papers\n",
    "model = word2Vec.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vector for the question\n",
    "questions_clean = model.transform(questions_clean)\n",
    "ques_vec = questions_clean.first().word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between a document vector and a question vector\n",
    "def cossim(doc_vec): \n",
    "    global ques_vec\n",
    "    sim = np.dot(doc_vec, ques_vec) / np.sqrt(np.dot(doc_vec, ques_vec)) / np.sqrt(np.dot(doc_vec, ques_vec)) \n",
    "    return float(sim)\n",
    "\n",
    "cossim_udf = udf(cossim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Effectiveness of inter inner travel restriction\n",
      "\n",
      "Relevant Papers:\n",
      "\n",
      "+---+--------------------+------------------+\n",
      "| id|            paper_id|        similarity|\n",
      "+---+--------------------+------------------+\n",
      "|412|0fa6e26b053037098...|1.0000000000000002|\n",
      "|382|a3f69a45be4bf642b...|1.0000000000000002|\n",
      "| 87|872a34dc8f89a091d...|1.0000000000000002|\n",
      "|185|72ab1b77e1ea96069...|1.0000000000000002|\n",
      "|101|f2b8d478a21a63e3c...|1.0000000000000002|\n",
      "|365|49d58cfebcb62abd1...|1.0000000000000002|\n",
      "|358|e161b910c1411b6d4...|1.0000000000000002|\n",
      "|144|c4213fb7b0fdd8926...|1.0000000000000002|\n",
      "| 62|249562b091482dd3e...|1.0000000000000002|\n",
      "|457|ce707aeb4fe129ed6...|1.0000000000000002|\n",
      "+---+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity between all papers and the selected question\n",
    "df_relevant = df.select('id', 'paper_id', cossim_udf('word_vector').alias('similarity'))\n",
    "\n",
    "# Remove questions from the paper list\n",
    "# Remove papers with a similarity of 'NaN'\n",
    "# Sort on cosine similarity\n",
    "# Take the top 10 relevant documents\n",
    "df_relevant = df_relevant.filter(df_relevant.id > 9) \\\n",
    "                            .filter(df_relevant.similarity != 'NaN') \\\n",
    "                            .sort(col('similarity').desc()) \\\n",
    "                            .limit(10)\n",
    "\n",
    "# Get the data of the 10 most relevant papers in order of relevance\n",
    "print(\"Query: {}\".format(q))\n",
    "print()\n",
    "print(\"Relevant Papers:\")\n",
    "print()\n",
    "df_relevant.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2b8d478a21a63e3c986ccbd0bfafc71578252d0</td>\n",
       "      <td>2020-05-30</td>\n",
       "      <td>COVID-19 panic, solidarity and equity‚Äîthe Malt...</td>\n",
       "      <td>10.1007/s10389-020-01308-w</td>\n",
       "      <td>Z Gesundh Wiss</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e161b910c1411b6d44fb63dbb5534dda132d44cd</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>Optimal size of sample pooling for RNA pool te...</td>\n",
       "      <td>10.1101/2020.06.11.20128793</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce707aeb4fe129ed6e3b011c2776f48b9cb200d6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d96113a2d8691d3b1aee5fd1b5d30241f2b2a633</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>Quantify the role of superspreaders -opinion l...</td>\n",
       "      <td>10.1371/journal.pone.0234023</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4213fb7b0fdd8926e9e4108726524bc87483677</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Forecasting COVID-19 new cases in Algeria usin...</td>\n",
       "      <td>10.1101/2020.05.03.20089615</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dc57cacedbbad71644464158ec9a2d61afbaeb70</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>Surgical treatment of thoracolumbar fracture w...</td>\n",
       "      <td>10.1016/j.cjtee.2020.05.005</td>\n",
       "      <td>Chin J Traumatol</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a3f69a45be4bf642b2375f5df6218fe9bb087f92</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>Managing business relationships during a pande...</td>\n",
       "      <td>10.1016/j.indmarman.2020.05.025</td>\n",
       "      <td>Industrial Marketing Management</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>249562b091482dd3e0ca8bdc45ea1d7c52ba1616</td>\n",
       "      <td>2014-04-13</td>\n",
       "      <td>Viral Respiratory Infections Diagnosed by Mult...</td>\n",
       "      <td>10.1016/j.bbmt.2014.04.004</td>\n",
       "      <td>Biol Blood Marrow Transplant</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49d58cfebcb62abd1286784f0bc3142ac91e4026</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>Chapter 45 Gender Differences in Emerging Infe...</td>\n",
       "      <td>10.1016/b978-0-12-374271-1.00045-9</td>\n",
       "      <td>Principles of Gender-Specific Medicine</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>872a34dc8f89a091dbf8f6280c6947fca7e14e2c</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Older age is associated with sustained detecti...</td>\n",
       "      <td>10.1101/2020.05.28.20115378</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id publish_time  \\\n",
       "0  f2b8d478a21a63e3c986ccbd0bfafc71578252d0   2020-05-30   \n",
       "1  e161b910c1411b6d44fb63dbb5534dda132d44cd   2020-06-14   \n",
       "2  ce707aeb4fe129ed6e3b011c2776f48b9cb200d6         None   \n",
       "3  d96113a2d8691d3b1aee5fd1b5d30241f2b2a633   2020-06-08   \n",
       "4  c4213fb7b0fdd8926e9e4108726524bc87483677   2020-05-08   \n",
       "5  dc57cacedbbad71644464158ec9a2d61afbaeb70   2020-05-21   \n",
       "6  a3f69a45be4bf642b2375f5df6218fe9bb087f92   2020-07-31   \n",
       "7  249562b091482dd3e0ca8bdc45ea1d7c52ba1616   2014-04-13   \n",
       "8  49d58cfebcb62abd1286784f0bc3142ac91e4026   2010-12-31   \n",
       "9  872a34dc8f89a091dbf8f6280c6947fca7e14e2c   2020-05-29   \n",
       "\n",
       "                                               title  \\\n",
       "0  COVID-19 panic, solidarity and equity‚Äîthe Malt...   \n",
       "1  Optimal size of sample pooling for RNA pool te...   \n",
       "2                                               None   \n",
       "3  Quantify the role of superspreaders -opinion l...   \n",
       "4  Forecasting COVID-19 new cases in Algeria usin...   \n",
       "5  Surgical treatment of thoracolumbar fracture w...   \n",
       "6  Managing business relationships during a pande...   \n",
       "7  Viral Respiratory Infections Diagnosed by Mult...   \n",
       "8  Chapter 45 Gender Differences in Emerging Infe...   \n",
       "9  Older age is associated with sustained detecti...   \n",
       "\n",
       "                                  doi                                 journal  \\\n",
       "0          10.1007/s10389-020-01308-w                          Z Gesundh Wiss   \n",
       "1         10.1101/2020.06.11.20128793                                    None   \n",
       "2                                None                                    None   \n",
       "3        10.1371/journal.pone.0234023                                PLoS One   \n",
       "4         10.1101/2020.05.03.20089615                                    None   \n",
       "5         10.1016/j.cjtee.2020.05.005                        Chin J Traumatol   \n",
       "6     10.1016/j.indmarman.2020.05.025         Industrial Marketing Management   \n",
       "7          10.1016/j.bbmt.2014.04.004            Biol Blood Marrow Transplant   \n",
       "8  10.1016/b978-0-12-374271-1.00045-9  Principles of Gender-Specific Medicine   \n",
       "9         10.1101/2020.05.28.20115378                                    None   \n",
       "\n",
       "           similarity  \n",
       "0  1.0000000000000002  \n",
       "1  1.0000000000000002  \n",
       "2  1.0000000000000002  \n",
       "3  1.0000000000000002  \n",
       "4  1.0000000000000002  \n",
       "5  1.0000000000000002  \n",
       "6  1.0000000000000002  \n",
       "7  1.0000000000000002  \n",
       "8  1.0000000000000002  \n",
       "9  1.0000000000000002  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the summary table with the relevant paper from the metadata\n",
    "df_relevant = df_relevant.join(df_metadata, on=['paper_id'], how='left_outer') \\\n",
    "                            .select('paper_id', 'publish_time', 'title', 'doi', 'journal', 'similarity') \\\n",
    "                            .toPandas() \\\n",
    "                            .sort_values(by='similarity', ascending=False)\n",
    "df_relevant.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table extracted and sent to csv file.\n"
     ]
    }
   ],
   "source": [
    "# Send the summary table to a csv file\n",
    "df_relevant.to_csv('/home/rikz/Documents/Master/Semester2/SDDM/SDDM/summary_tables/word2vec/{}.csv' \\\n",
    "                   .format(q.lower().replace(' ', '_')), index=False)\n",
    "print(\"Summary table extracted and sent to csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
